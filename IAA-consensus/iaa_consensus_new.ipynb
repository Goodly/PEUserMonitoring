{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# New IAA consensus answer file from IAA and tag container\n",
    "schema = pd.read_csv('Covid_Evidence2020_03_21-Schema.csv')\n",
    "iaa = pd.read_csv('Covid_Evidencev1.IAA-2020-11-17T0612-Tags.csv')\n",
    "\n",
    "answers = iaa.merge(schema, how=\"left\", on=\"answer_uuid\")\n",
    "answers = answers[[\"article_sha256\", \"schema_sha256\", \"answer_uuid\", \"source_task_uuid\",\n",
    "                     \"target_text\", \"question_uuid\", \"question_label\", \"answer_label\",\n",
    "                     \"question_type\", \"answer_count\"]]\n",
    "\n",
    "answers = answers.replace(np.nan, '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that takes in  **question_label**, **source_task_uuid/quiz_task_uuid**, and **target_text**, and returns a list of all the corresponding consensus answers. This could be an empty list if there is no consensus for that question, a length one list if the question is a \"select one\" question (including ordinal questions), or a list of multiple answers if it is a \"select one\"/checkbox question.\n",
    "\n",
    "If consensus answers exist, they will be in the form T1.Q_.A_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_consensus(question_label, quiz_task_uuid, target_text):\n",
    "    answer_df = answers.loc[(answers[\"question_label\"] == question_label)\n",
    "                         & (answers[\"source_task_uuid\"] == quiz_task_uuid)\n",
    "                         & (answers[\"target_text\"] == target_text)]\n",
    "    \n",
    "    return answer_df[\"answer_label\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T1.Q2.A2', 'T1.Q2.A3']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checklist example\n",
    "get_consensus('T1.Q2',\n",
    "              '5985e15b-66bd-41c5-9659-86fab8376b8d',\n",
    "              '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T1.Q9.A3']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Select one\" example\n",
    "get_consensus('T1.Q9',\n",
    "              'bb5c9329-144f-4d11-b54f-ca30121028a4',\n",
    "              'For COVID-19, the R0 is estimated to be 3.28, though studies are still ongoing and this number will probably change. This means that for herd immunity, about 70% of the UK population would need to be immune to COVID-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that takes in  **question_label**, **source_task_uuid/quiz_task_uuid**, and **target_text**, and returns a **tuple containing the question type and number of answer choices, will help with scoring questions**.\n",
    "\n",
    "If the question_type and num_answer_choices works as expected, we shouldn't need to hardcode the question schema data anymore.\n",
    "\n",
    "Returned question type will be one of:  \n",
    "RADIO  \n",
    "CHECKBOX  \n",
    "SELECT_SUBTOPIC  \n",
    "TEXT  \n",
    "DATE  \n",
    "TIME  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question_meta(question_label, quiz_task_uuid, target_text):\n",
    "    answer_df = answers.loc[(answers[\"question_label\"] == question_label)\n",
    "                         & (answers[\"source_task_uuid\"] == quiz_task_uuid)\n",
    "                         & (answers[\"target_text\"] == target_text)]\n",
    "    \n",
    "    return (answer_df[\"question_type\"].iloc[0], answer_df[\"answer_count\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CHECKBOX', 9)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_question_meta('T1.Q2',\n",
    "              '5985e15b-66bd-41c5-9659-86fab8376b8d',\n",
    "              '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('RADIO', 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_question_meta('T1.Q9',\n",
    "              'bb5c9329-144f-4d11-b54f-ca30121028a4',\n",
    "              'For COVID-19, the R0 is estimated to be 3.28, though studies are still ongoing and this number will probably change. This means that for herd immunity, about 70% of the UK population would need to be immune to COVID-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
