{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_num</th>\n",
       "      <th>article_sha256</th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_filename</th>\n",
       "      <th>source_task_uuid</th>\n",
       "      <th>tua_uuid</th>\n",
       "      <th>namespace</th>\n",
       "      <th>schema_sha256</th>\n",
       "      <th>question_Number</th>\n",
       "      <th>answer_uuid</th>\n",
       "      <th>...</th>\n",
       "      <th>agreed_Answer</th>\n",
       "      <th>coding_perc_agreement</th>\n",
       "      <th>highlighted_indices</th>\n",
       "      <th>agreement_score</th>\n",
       "      <th>num_users</th>\n",
       "      <th>num_answer_choices</th>\n",
       "      <th>target_text</th>\n",
       "      <th>question_text</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>answer_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100059</td>\n",
       "      <td>4b537e0ed21179a29ed28da28057d338e67330ae12123c...</td>\n",
       "      <td>raw_304b537e0ed21179a29ed28da28057d338e67330ae...</td>\n",
       "      <td>Covid_article_for_PE_S&amp;S&amp;S.txt</td>\n",
       "      <td>270ea60c-f961-402b-96d5-c015fac1960d</td>\n",
       "      <td>a23b77bd-9eae-4050-9b5d-e38ecb126226</td>\n",
       "      <td>Covid_Evidence2020_03_21</td>\n",
       "      <td>45dce5251bd3ea6e908fa33ac9e6a8e17e6830215912ce...</td>\n",
       "      <td>1</td>\n",
       "      <td>73d7a14a-9ec6-404c-b2b7-a55508af3b76</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[3764, 3765, 3766, 3767, 3768, 3769, 3770, 377...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>EspeciallyÂ at risk are the elderly, who both ...</td>\n",
       "      <td>Is a general or singular causal claim made? Hi...</td>\n",
       "      <td>General Causation (In general, X causes Y.)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100059</td>\n",
       "      <td>4b537e0ed21179a29ed28da28057d338e67330ae12123c...</td>\n",
       "      <td>raw_304b537e0ed21179a29ed28da28057d338e67330ae...</td>\n",
       "      <td>Covid_article_for_PE_S&amp;S&amp;S.txt</td>\n",
       "      <td>270ea60c-f961-402b-96d5-c015fac1960d</td>\n",
       "      <td>a23b77bd-9eae-4050-9b5d-e38ecb126226</td>\n",
       "      <td>Covid_Evidence2020_03_21</td>\n",
       "      <td>45dce5251bd3ea6e908fa33ac9e6a8e17e6830215912ce...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>L</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>Is a general or singular causal claim made? Hi...</td>\n",
       "      <td>L</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100059</td>\n",
       "      <td>4b537e0ed21179a29ed28da28057d338e67330ae12123c...</td>\n",
       "      <td>raw_304b537e0ed21179a29ed28da28057d338e67330ae...</td>\n",
       "      <td>Covid_article_for_PE_S&amp;S&amp;S.txt</td>\n",
       "      <td>270ea60c-f961-402b-96d5-c015fac1960d</td>\n",
       "      <td>a23b77bd-9eae-4050-9b5d-e38ecb126226</td>\n",
       "      <td>Covid_Evidence2020_03_21</td>\n",
       "      <td>45dce5251bd3ea6e908fa33ac9e6a8e17e6830215912ce...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>L</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>Is a general or singular causal claim made? Hi...</td>\n",
       "      <td>L</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_num                                     article_sha256  \\\n",
       "0       100059  4b537e0ed21179a29ed28da28057d338e67330ae12123c...   \n",
       "1       100059  4b537e0ed21179a29ed28da28057d338e67330ae12123c...   \n",
       "2       100059  4b537e0ed21179a29ed28da28057d338e67330ae12123c...   \n",
       "\n",
       "                                          article_id  \\\n",
       "0  raw_304b537e0ed21179a29ed28da28057d338e67330ae...   \n",
       "1  raw_304b537e0ed21179a29ed28da28057d338e67330ae...   \n",
       "2  raw_304b537e0ed21179a29ed28da28057d338e67330ae...   \n",
       "\n",
       "                 article_filename                      source_task_uuid  \\\n",
       "0  Covid_article_for_PE_S&S&S.txt  270ea60c-f961-402b-96d5-c015fac1960d   \n",
       "1  Covid_article_for_PE_S&S&S.txt  270ea60c-f961-402b-96d5-c015fac1960d   \n",
       "2  Covid_article_for_PE_S&S&S.txt  270ea60c-f961-402b-96d5-c015fac1960d   \n",
       "\n",
       "                               tua_uuid                 namespace  \\\n",
       "0  a23b77bd-9eae-4050-9b5d-e38ecb126226  Covid_Evidence2020_03_21   \n",
       "1  a23b77bd-9eae-4050-9b5d-e38ecb126226  Covid_Evidence2020_03_21   \n",
       "2  a23b77bd-9eae-4050-9b5d-e38ecb126226  Covid_Evidence2020_03_21   \n",
       "\n",
       "                                       schema_sha256  question_Number  \\\n",
       "0  45dce5251bd3ea6e908fa33ac9e6a8e17e6830215912ce...                1   \n",
       "1  45dce5251bd3ea6e908fa33ac9e6a8e17e6830215912ce...                1   \n",
       "2  45dce5251bd3ea6e908fa33ac9e6a8e17e6830215912ce...                1   \n",
       "\n",
       "                            answer_uuid  ... agreed_Answer  \\\n",
       "0  73d7a14a-9ec6-404c-b2b7-a55508af3b76  ...             1   \n",
       "1                                     0  ...             L   \n",
       "2                                     0  ...             L   \n",
       "\n",
       "  coding_perc_agreement                                highlighted_indices  \\\n",
       "0                   1.0  [3764, 3765, 3766, 3767, 3768, 3769, 3770, 377...   \n",
       "1                   0.0                                                 []   \n",
       "2                   0.0                                                 []   \n",
       "\n",
       "  agreement_score  num_users  num_answer_choices  \\\n",
       "0             1.0          3                   3   \n",
       "1             0.0          3                   3   \n",
       "2             0.0          3                   3   \n",
       "\n",
       "                                         target_text  \\\n",
       "0  EspeciallyÂ at risk are the elderly, who both ...   \n",
       "1                                                  L   \n",
       "2                                                  L   \n",
       "\n",
       "                                       question_text  \\\n",
       "0  Is a general or singular causal claim made? Hi...   \n",
       "1  Is a general or singular causal claim made? Hi...   \n",
       "2  Is a general or singular causal claim made? Hi...   \n",
       "\n",
       "                                   answer_text answer_content  \n",
       "0  General Causation (In general, X causes Y.)            NaN  \n",
       "1                                            L            NaN  \n",
       "2                                            L            NaN  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demo data file from Eric (example of output from IAA)\n",
    "iaa = pd.read_csv(\"IAA-file-demo.csv\").head(3)\n",
    "iaa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important columns:\n",
    "- article_num (maybe not needed)\n",
    "- article_sha256 (part of unique answer identifier)\n",
    "- tua_uuid (part of unique answer identifier)\n",
    "- schema_namespace (human readable schema type)\n",
    "- schema_sha256 (part of unique answer identifier)\n",
    "- num_answer_choices (helpful for scoring ordinal questions)\n",
    "- question_Number (part of unique answer identifier)\n",
    "- answer_uuid (what we want to find)\n",
    "- agreed_answer (is a number if )\n",
    "- question_type (checklist, nominal, ordinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that takes in **article_sha256** (string), **tua_uuid** (string), **schema_sha256** (string), and **question_Number** (int), and returns the **corresponding consensus answer** from IAA.\n",
    "\n",
    "The return value is a single int instead of the \"T1.Q1.A1\" format because I believe IAA processes and outputs just the number. \n",
    "\n",
    "(also let me know if there's a more efficient way to index the df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_consensus(article_sha256, tua_uuid, schema_sha256, question_Number):\n",
    "    answer_row = iaa.loc[(iaa[\"article_sha256\"] == article_sha256)\n",
    "                         & (iaa[\"tua_uuid\"] == tua_uuid)\n",
    "                         & (iaa[\"schema_sha256\"] == schema_sha256)\n",
    "                         & (iaa[\"question_Number\"] == question_Number)]\n",
    "    \n",
    "    if (answer_row[\"agreed_Answer\"].iloc[0].isdigit()):\n",
    "        return int(answer_row[\"agreed_Answer\"].iloc[0])\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_consensus('4b537e0ed21179a29ed28da28057d338e67330ae12123ccceba6724f35bd68a4',\n",
    "              'a23b77bd-9eae-4050-9b5d-e38ecb126226',\n",
    "              '45dce5251bd3ea6e908fa33ac9e6a8e17e6830215912ce1626cf4206e159819c',\n",
    "              1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that takes in **article_sha256** (string), **tua_uuid** (string), **schema_sha256** (string), and **question_Number** (int), and returns a **tuple containing the question type and number of answer choices, will help with scoring questions**.\n",
    "\n",
    "If the question_type and num_answer_choices works as expected, we shouldn't need to hardcode the question schema data anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question_meta(article_sha256, tua_uuid, schema_sha256, question_Number):\n",
    "    answer_row = iaa.loc[(iaa[\"article_sha256\"] == article_sha256)\n",
    "                         & (iaa[\"tua_uuid\"] == tua_uuid)\n",
    "                         & (iaa[\"schema_sha256\"] == schema_sha256)\n",
    "                         & (iaa[\"question_Number\"] == question_Number)]\n",
    "    \n",
    "    return (answer_row[\"question_type\"].iloc[0], answer_row[\"num_answer_choices\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('checklist', 3)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_question_meta('4b537e0ed21179a29ed28da28057d338e67330ae12123ccceba6724f35bd68a4',\n",
    "              'a23b77bd-9eae-4050-9b5d-e38ecb126226',\n",
    "              '45dce5251bd3ea6e908fa33ac9e6a8e17e6830215912ce1626cf4206e159819c',\n",
    "              1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
